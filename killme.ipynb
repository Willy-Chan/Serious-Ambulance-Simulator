{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 00:43:21.876037: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "4\n",
      "[<tensorflow.python.keras.layers.core.Dense object at 0x7f01fe9223d0>, <tensorflow.python.keras.layers.core.Dense object at 0x7f01f1811850>, <tensorflow.python.keras.layers.core.Dense object at 0x7f01f1811b20>, <tensorflow.python.keras.layers.core.Dense object at 0x7f01f1811e50>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 00:43:24.987146: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-29 00:43:33.581577: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-07-29 00:43:33.581625: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (gabrielhan): /proc/driver/nvidia/version does not exist\n",
      "2021-07-29 00:43:33.583037: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf_agents.policies.random_tf_policy.RandomTFPolicy object at 0x7f01f06b07c0>\n",
      "TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': BoundedTensorSpec(shape=(121,), dtype=tf.float32, name='observation', minimum=array(0., dtype=float32), maximum=array(1000., dtype=float32)),\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(3, dtype=int32))\n",
      "TimeStep(\n",
      "{'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
      " 'observation': <tf.Tensor: shape=(1, 121), dtype=float32, numpy=\n",
      "array([[200., 200., 200., 200., 200., 200., 200., 200., 200., 200., 200.,\n",
      "        200., 300., 300., 300., 301., 600., 200., 300., 301., 300., 200.,\n",
      "        200., 300., 300., 200., 200., 200., 200., 300., 300., 300., 200.,\n",
      "        200., 300., 300., 300., 300., 300., 300., 303., 300., 300., 200.,\n",
      "        200., 300., 303., 300., 300., 301., 300., 300., 300., 300., 200.,\n",
      "        200., 300., 305., 301., 301., 301., 301., 301., 303., 301., 200.,\n",
      "        200., 300., 300., 301., 300., 200., 200., 200., 300., 300., 200.,\n",
      "        200., 300., 300., 300., 300., 200., 300., 300., 300., 300., 200.,\n",
      "        200., 300., 300., 300., 300., 200., 300., 300., 301., 300., 200.,\n",
      "        200., 300., 300., 300., 300., 200., 300., 300., 303., 300., 200.,\n",
      "        200., 200., 200., 200., 200., 200., 200., 200., 200., 200., 200.]],\n",
      "      dtype=float32)>,\n",
      " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
      " 'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>})\n",
      "WARNING:tensorflow:From /home/gabrielhan/PycharmProjects/bwsi/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:382: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n",
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f01f06813a0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 00:43:37.824219: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-29 00:43:37.843856: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 1497600000 Hz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import gym_sgw\n",
    "import gym\n",
    "from gym_sgw.envs.SGWEnv import SGW\n",
    "from tf_agents.environments import utils\n",
    "\n",
    "num_iterations = 10000000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 10000  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 10000  # @param {type:\"integer\"}\n",
    "\n",
    "train_py_env = SGW()\n",
    "eval_py_env = SGW()\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n",
    "\n",
    "fc_layer_params = (100, 80, 50, 20)\n",
    "action_tensor_spec = tensor_spec.from_spec(train_py_env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "print(num_actions)\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "  return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# it's output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "print(dense_layers)\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()\n",
    "\n",
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n",
    "\n",
    "print(random_policy)\n",
    "\n",
    "example_environment = tf_py_environment.TFPyEnvironment(SGW())\n",
    "\n",
    "\n",
    "\n",
    "time_step = example_environment.reset()\n",
    "\n",
    "print(train_env.time_step_spec())\n",
    "print(train_env.action_spec())\n",
    "print(time_step)\n",
    "random_policy.action(time_step)\n",
    "\n",
    "#@test {\"skip\": true}\n",
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics\n",
    "\n",
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)\n",
    "\n",
    "#@test {\"skip\": true}\n",
    "def collect_step(environment, policy, buffer):\n",
    "  time_step = environment.current_time_step()\n",
    "  action_step = policy.action(time_step)\n",
    "  next_time_step = environment.step(action_step.action)\n",
    "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "  # Add trajectory to the replay buffer\n",
    "  buffer.add_batch(traj)\n",
    "\n",
    "def collect_data(env, policy, buffer, steps):\n",
    "  for _ in range(steps):\n",
    "    collect_step(env, policy, buffer)\n",
    "\n",
    "collect_data(train_env, random_policy, replay_buffer, initial_collect_steps)\n",
    "\n",
    "# This loop is so common in RL, that we provide standard implementations. \n",
    "# For more details see tutorial 4 or the drivers module.\n",
    "# https://github.com/tensorflow/agents/blob/master/docs/tutorials/4_drivers_tutorial.ipynb \n",
    "# https://www.tensorflow.org/agents/api_docs/python/tf_agents/drivers\n",
    "\n",
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, \n",
    "    sample_batch_size=batch_size, \n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "\n",
    "iterator = iter(dataset)\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gabrielhan/PycharmProjects/bwsi/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
      "step = 10000: loss = 0.0\n",
      "step = 10000: Average Return = 0.0\n",
      "step = 20000: loss = 0.0\n",
      "step = 20000: Average Return = 0.0\n",
      "step = 30000: loss = 0.0\n",
      "step = 30000: Average Return = 0.0\n",
      "step = 40000: loss = 0.0\n",
      "step = 40000: Average Return = 0.0\n",
      "step = 50000: loss = 0.0\n",
      "step = 50000: Average Return = 100.0\n",
      "step = 60000: loss = 0.0\n",
      "step = 60000: Average Return = 100.0\n",
      "step = 70000: loss = 0.0\n",
      "step = 70000: Average Return = 100.0\n",
      "step = 80000: loss = 0.0\n",
      "step = 80000: Average Return = 0.0\n",
      "step = 90000: loss = 0.0\n",
      "step = 90000: Average Return = 100.0\n",
      "step = 100000: loss = 0.0\n",
      "step = 100000: Average Return = 0.0\n",
      "step = 110000: loss = 0.0\n",
      "step = 110000: Average Return = 0.0\n",
      "step = 120000: loss = 0.0\n",
      "step = 120000: Average Return = 0.0\n",
      "step = 130000: loss = 0.0\n",
      "step = 130000: Average Return = 0.0\n",
      "step = 140000: loss = 0.0\n",
      "step = 140000: Average Return = 0.0\n",
      "step = 150000: loss = 0.0\n",
      "step = 150000: Average Return = 0.0\n",
      "step = 160000: loss = 0.0\n",
      "step = 160000: Average Return = 0.0\n",
      "step = 170000: loss = 0.0\n",
      "step = 170000: Average Return = 0.0\n",
      "step = 180000: loss = 0.0\n",
      "step = 180000: Average Return = 0.0\n",
      "step = 190000: loss = 0.0\n",
      "step = 190000: Average Return = 0.0\n",
      "step = 200000: loss = 0.0\n",
      "step = 200000: Average Return = 0.0\n",
      "step = 210000: loss = 0.0\n",
      "step = 210000: Average Return = 0.0\n",
      "step = 220000: loss = 0.0\n",
      "step = 220000: Average Return = 0.0\n",
      "step = 230000: loss = 0.0\n",
      "step = 230000: Average Return = 0.0\n",
      "step = 240000: loss = 0.0\n",
      "step = 240000: Average Return = 0.0\n",
      "step = 250000: loss = 0.0\n",
      "step = 250000: Average Return = 0.0\n",
      "step = 260000: loss = 0.0\n",
      "step = 260000: Average Return = 0.0\n",
      "step = 270000: loss = 0.0\n",
      "step = 270000: Average Return = 0.0\n",
      "step = 280000: loss = 0.0\n",
      "step = 280000: Average Return = 0.0\n",
      "step = 290000: loss = 0.0\n",
      "step = 290000: Average Return = 0.0\n",
      "step = 300000: loss = 0.0\n",
      "step = 300000: Average Return = 0.0\n",
      "step = 310000: loss = 0.0\n",
      "step = 310000: Average Return = 0.0\n",
      "step = 320000: loss = 0.0\n",
      "step = 320000: Average Return = 0.0\n",
      "step = 330000: loss = 0.0\n",
      "step = 330000: Average Return = 0.0\n",
      "step = 340000: loss = 0.0\n",
      "step = 340000: Average Return = 0.0\n",
      "step = 350000: loss = 0.0\n",
      "step = 350000: Average Return = 0.0\n",
      "step = 360000: loss = 0.0\n",
      "step = 360000: Average Return = 0.0\n",
      "step = 370000: loss = 0.0\n",
      "step = 370000: Average Return = 0.0\n",
      "step = 380000: loss = 0.0\n",
      "step = 380000: Average Return = 0.0\n",
      "step = 390000: loss = 0.0\n",
      "step = 390000: Average Return = 0.0\n",
      "step = 400000: loss = 0.0\n",
      "step = 400000: Average Return = 0.0\n",
      "step = 410000: loss = 0.0\n",
      "step = 410000: Average Return = 0.0\n",
      "step = 420000: loss = 0.0\n",
      "step = 420000: Average Return = 0.0\n",
      "step = 430000: loss = 0.0\n",
      "step = 430000: Average Return = 0.0\n",
      "step = 440000: loss = 0.0\n",
      "step = 440000: Average Return = 0.0\n",
      "step = 450000: loss = 0.0\n",
      "step = 450000: Average Return = 0.0\n",
      "step = 460000: loss = 0.0\n",
      "step = 460000: Average Return = 0.0\n",
      "step = 470000: loss = 0.0\n",
      "step = 470000: Average Return = 0.0\n",
      "step = 480000: loss = 0.0\n",
      "step = 480000: Average Return = 0.0\n",
      "step = 490000: loss = 0.0\n",
      "step = 490000: Average Return = 0.0\n",
      "step = 500000: loss = 0.0\n",
      "step = 500000: Average Return = 0.0\n",
      "step = 510000: loss = 0.0\n",
      "step = 510000: Average Return = 0.0\n",
      "step = 520000: loss = 0.0\n",
      "step = 520000: Average Return = 0.0\n",
      "step = 530000: loss = 0.0\n",
      "step = 530000: Average Return = 0.0\n",
      "step = 540000: loss = 0.0\n",
      "step = 540000: Average Return = 0.0\n",
      "step = 550000: loss = 0.0\n",
      "step = 550000: Average Return = 0.0\n",
      "step = 560000: loss = 0.0\n",
      "step = 560000: Average Return = 0.0\n",
      "step = 570000: loss = 0.0\n",
      "step = 570000: Average Return = 0.0\n",
      "step = 580000: loss = 0.0\n",
      "step = 580000: Average Return = 0.0\n",
      "step = 590000: loss = 0.0\n",
      "step = 590000: Average Return = 0.0\n",
      "step = 600000: loss = 0.0\n",
      "step = 600000: Average Return = 0.0\n",
      "step = 610000: loss = 0.0\n",
      "step = 610000: Average Return = 0.0\n",
      "step = 620000: loss = 0.0\n",
      "step = 620000: Average Return = 0.0\n",
      "step = 630000: loss = 0.0\n",
      "step = 630000: Average Return = 0.0\n",
      "step = 640000: loss = 0.0\n",
      "step = 640000: Average Return = 0.0\n",
      "step = 650000: loss = 0.0\n",
      "step = 650000: Average Return = 0.0\n",
      "step = 660000: loss = 0.0\n",
      "step = 660000: Average Return = 0.0\n",
      "step = 670000: loss = 0.0\n",
      "step = 670000: Average Return = 0.0\n",
      "step = 680000: loss = 0.0\n",
      "step = 680000: Average Return = 0.0\n",
      "step = 690000: loss = 0.0\n",
      "step = 690000: Average Return = 0.0\n",
      "step = 700000: loss = 0.0\n",
      "step = 700000: Average Return = 0.0\n",
      "step = 710000: loss = 0.0\n",
      "step = 710000: Average Return = 0.0\n",
      "step = 720000: loss = 0.0\n",
      "step = 720000: Average Return = 0.0\n",
      "step = 730000: loss = 0.0\n",
      "step = 730000: Average Return = 0.0\n",
      "step = 740000: loss = 0.0\n",
      "step = 740000: Average Return = 0.0\n",
      "step = 750000: loss = 0.0\n",
      "step = 750000: Average Return = 0.0\n",
      "step = 760000: loss = 0.0\n",
      "step = 760000: Average Return = 0.0\n",
      "step = 770000: loss = 0.0\n",
      "step = 770000: Average Return = 0.0\n",
      "step = 780000: loss = 0.0\n",
      "step = 780000: Average Return = 0.0\n",
      "step = 790000: loss = 0.0\n",
      "step = 790000: Average Return = 0.0\n",
      "step = 800000: loss = 0.0\n",
      "step = 800000: Average Return = 0.0\n",
      "step = 810000: loss = 0.0\n",
      "step = 810000: Average Return = 0.0\n",
      "step = 820000: loss = 0.0\n",
      "step = 820000: Average Return = 0.0\n",
      "step = 830000: loss = 0.0\n",
      "step = 830000: Average Return = 0.0\n",
      "step = 840000: loss = 0.0\n",
      "step = 840000: Average Return = 0.0\n",
      "step = 850000: loss = 0.0\n",
      "step = 850000: Average Return = 0.0\n",
      "step = 860000: loss = 0.0\n",
      "step = 860000: Average Return = 0.0\n",
      "step = 870000: loss = 0.0\n",
      "step = 870000: Average Return = 0.0\n",
      "step = 880000: loss = 0.0\n",
      "step = 880000: Average Return = 0.0\n",
      "step = 890000: loss = 0.0\n",
      "step = 890000: Average Return = 0.0\n",
      "step = 900000: loss = 0.0\n",
      "step = 900000: Average Return = 0.0\n",
      "step = 910000: loss = 0.0\n",
      "step = 910000: Average Return = 0.0\n",
      "step = 920000: loss = 0.0\n",
      "step = 920000: Average Return = 0.0\n",
      "step = 930000: loss = 0.0\n",
      "step = 930000: Average Return = 0.0\n",
      "step = 940000: loss = 0.0\n",
      "step = 940000: Average Return = 0.0\n",
      "step = 950000: loss = 0.0\n",
      "step = 950000: Average Return = 0.0\n",
      "step = 960000: loss = 0.0\n",
      "step = 960000: Average Return = 0.0\n",
      "step = 970000: loss = 0.0\n",
      "step = 970000: Average Return = 0.0\n",
      "step = 980000: loss = 0.0\n",
      "step = 980000: Average Return = 0.0\n",
      "step = 990000: loss = 0.0\n",
      "step = 990000: Average Return = 0.0\n",
      "step = 1000000: loss = 0.0\n",
      "step = 1000000: Average Return = 0.0\n",
      "step = 1010000: loss = 0.0\n",
      "step = 1010000: Average Return = 0.0\n",
      "step = 1020000: loss = 0.0\n",
      "step = 1020000: Average Return = 0.0\n",
      "step = 1030000: loss = 0.0\n",
      "step = 1030000: Average Return = 0.0\n",
      "step = 1040000: loss = 0.0\n",
      "step = 1040000: Average Return = 0.0\n",
      "step = 1050000: loss = 0.0\n",
      "step = 1050000: Average Return = 0.0\n",
      "step = 1060000: loss = 0.0\n",
      "step = 1060000: Average Return = 0.0\n",
      "step = 1070000: loss = 0.0\n",
      "step = 1070000: Average Return = 0.0\n",
      "step = 1080000: loss = 0.0\n",
      "step = 1080000: Average Return = 0.0\n",
      "step = 1090000: loss = 0.0\n",
      "step = 1090000: Average Return = 0.0\n",
      "step = 1100000: loss = 0.0\n",
      "step = 1100000: Average Return = 0.0\n",
      "step = 1110000: loss = 0.0\n",
      "step = 1110000: Average Return = 0.0\n",
      "step = 1120000: loss = 0.0\n",
      "step = 1120000: Average Return = 0.0\n",
      "step = 1130000: loss = 0.0\n",
      "step = 1130000: Average Return = 0.0\n",
      "step = 1140000: loss = 0.0\n",
      "step = 1140000: Average Return = 0.0\n",
      "step = 1150000: loss = 0.0\n",
      "step = 1150000: Average Return = 0.0\n",
      "step = 1160000: loss = 0.0\n",
      "step = 1160000: Average Return = 0.0\n",
      "step = 1170000: loss = 0.0\n",
      "step = 1170000: Average Return = 0.0\n",
      "step = 1180000: loss = 0.0\n",
      "step = 1180000: Average Return = 0.0\n",
      "step = 1190000: loss = 0.0\n",
      "step = 1190000: Average Return = 0.0\n",
      "step = 1200000: loss = 0.0\n",
      "step = 1200000: Average Return = 0.0\n",
      "step = 1210000: loss = 0.0\n",
      "step = 1210000: Average Return = 0.0\n",
      "step = 1220000: loss = 0.0\n",
      "step = 1220000: Average Return = 0.0\n",
      "step = 1230000: loss = 0.0\n",
      "step = 1230000: Average Return = 0.0\n",
      "step = 1240000: loss = 0.0\n",
      "step = 1240000: Average Return = 0.0\n",
      "step = 1250000: loss = 0.0\n",
      "step = 1250000: Average Return = 0.0\n",
      "step = 1260000: loss = 0.0\n",
      "step = 1260000: Average Return = 0.0\n",
      "step = 1270000: loss = 0.0\n",
      "step = 1270000: Average Return = 0.0\n",
      "step = 1280000: loss = 0.0\n",
      "step = 1280000: Average Return = 0.0\n",
      "step = 1290000: loss = 0.0\n",
      "step = 1290000: Average Return = 0.0\n",
      "step = 1300000: loss = 0.0\n",
      "step = 1300000: Average Return = 0.0\n",
      "step = 1310000: loss = 0.0\n",
      "step = 1310000: Average Return = 0.0\n",
      "step = 1320000: loss = 0.0\n",
      "step = 1320000: Average Return = 0.0\n",
      "step = 1330000: loss = 0.0\n",
      "step = 1330000: Average Return = 0.0\n",
      "step = 1340000: loss = 0.0\n",
      "step = 1340000: Average Return = 0.0\n",
      "step = 1350000: loss = 0.0\n",
      "step = 1350000: Average Return = 0.0\n",
      "step = 1360000: loss = 0.0\n",
      "step = 1360000: Average Return = 0.0\n",
      "step = 1370000: loss = 0.0\n",
      "step = 1370000: Average Return = 0.0\n",
      "step = 1380000: loss = 0.0\n",
      "step = 1380000: Average Return = 0.0\n",
      "step = 1390000: loss = 0.0\n",
      "step = 1390000: Average Return = 0.0\n",
      "step = 1400000: loss = 0.0\n",
      "step = 1400000: Average Return = 0.0\n",
      "step = 1410000: loss = 0.0\n",
      "step = 1410000: Average Return = 0.0\n",
      "step = 1420000: loss = 0.0\n",
      "step = 1420000: Average Return = 0.0\n",
      "step = 1430000: loss = 0.0\n",
      "step = 1430000: Average Return = 0.0\n",
      "step = 1440000: loss = 0.0\n",
      "step = 1440000: Average Return = 0.0\n",
      "step = 1450000: loss = 0.0\n",
      "step = 1450000: Average Return = 0.0\n",
      "step = 1460000: loss = 0.0\n",
      "step = 1460000: Average Return = 0.0\n",
      "step = 1470000: loss = 0.0\n",
      "step = 1470000: Average Return = 0.0\n",
      "step = 1480000: loss = 0.0\n",
      "step = 1480000: Average Return = 0.0\n",
      "step = 1490000: loss = 0.0\n",
      "step = 1490000: Average Return = 0.0\n",
      "step = 1500000: loss = 0.0\n",
      "step = 1500000: Average Return = 0.0\n",
      "step = 1510000: loss = 0.0\n",
      "step = 1510000: Average Return = 0.0\n",
      "step = 1520000: loss = 0.0\n",
      "step = 1520000: Average Return = 0.0\n",
      "step = 1530000: loss = 0.0\n",
      "step = 1530000: Average Return = 0.0\n",
      "step = 1540000: loss = 0.0\n",
      "step = 1540000: Average Return = 0.0\n",
      "step = 1550000: loss = 0.0\n",
      "step = 1550000: Average Return = 0.0\n",
      "step = 1560000: loss = 0.0\n",
      "step = 1560000: Average Return = 0.0\n",
      "step = 1570000: loss = 0.0\n",
      "step = 1570000: Average Return = 0.0\n",
      "step = 1580000: loss = 0.0\n",
      "step = 1580000: Average Return = 0.0\n",
      "step = 1590000: loss = 0.0\n",
      "step = 1590000: Average Return = 0.0\n",
      "step = 1600000: loss = 0.0\n",
      "step = 1600000: Average Return = 0.0\n",
      "step = 1610000: loss = 0.0\n",
      "step = 1610000: Average Return = 0.0\n",
      "step = 1620000: loss = 0.0\n",
      "step = 1620000: Average Return = 0.0\n",
      "step = 1630000: loss = 0.0\n",
      "step = 1630000: Average Return = 0.0\n",
      "step = 1640000: loss = 0.0\n",
      "step = 1640000: Average Return = 0.0\n",
      "step = 1650000: loss = 0.0\n",
      "step = 1650000: Average Return = 0.0\n",
      "step = 1660000: loss = 0.0\n",
      "step = 1660000: Average Return = 0.0\n",
      "step = 1670000: loss = 0.0\n",
      "step = 1670000: Average Return = 0.0\n",
      "step = 1680000: loss = 0.0\n",
      "step = 1680000: Average Return = 0.0\n",
      "step = 1690000: loss = 0.0\n",
      "step = 1690000: Average Return = 0.0\n",
      "step = 1700000: loss = 0.0\n",
      "step = 1700000: Average Return = 0.0\n",
      "step = 1710000: loss = 0.0\n",
      "step = 1710000: Average Return = 0.0\n",
      "step = 1720000: loss = 0.0\n",
      "step = 1720000: Average Return = 0.0\n",
      "step = 1730000: loss = 0.0\n",
      "step = 1730000: Average Return = 0.0\n",
      "step = 1740000: loss = 0.0\n",
      "step = 1740000: Average Return = 0.0\n",
      "step = 1750000: loss = 0.0\n",
      "step = 1750000: Average Return = 0.0\n",
      "step = 1760000: loss = 0.0\n",
      "step = 1760000: Average Return = 0.0\n",
      "step = 1770000: loss = 0.0\n",
      "step = 1770000: Average Return = 0.0\n",
      "step = 1780000: loss = 0.0\n",
      "step = 1780000: Average Return = 0.0\n",
      "step = 1790000: loss = 0.0\n",
      "step = 1790000: Average Return = 0.0\n",
      "step = 1800000: loss = 0.0\n",
      "step = 1800000: Average Return = 0.0\n",
      "step = 1810000: loss = 0.0\n",
      "step = 1810000: Average Return = 0.0\n",
      "step = 1820000: loss = 0.0\n",
      "step = 1820000: Average Return = 0.0\n",
      "step = 1830000: loss = 0.0\n",
      "step = 1830000: Average Return = 0.0\n",
      "step = 1840000: loss = 0.0\n",
      "step = 1840000: Average Return = 0.0\n",
      "step = 1850000: loss = 0.0\n",
      "step = 1850000: Average Return = 0.0\n",
      "step = 1860000: loss = 0.0\n",
      "step = 1860000: Average Return = 0.0\n",
      "step = 1870000: loss = 0.0\n",
      "step = 1870000: Average Return = 0.0\n",
      "step = 1880000: loss = 0.0\n",
      "step = 1880000: Average Return = 0.0\n",
      "step = 1890000: loss = 0.0\n",
      "step = 1890000: Average Return = 0.0\n",
      "step = 1900000: loss = 0.0\n",
      "step = 1900000: Average Return = 0.0\n",
      "step = 1910000: loss = 0.0\n",
      "step = 1910000: Average Return = 0.0\n",
      "step = 1920000: loss = 0.0\n",
      "step = 1920000: Average Return = 0.0\n",
      "step = 1930000: loss = 0.0\n",
      "step = 1930000: Average Return = 0.0\n",
      "step = 1940000: loss = 0.0\n",
      "step = 1940000: Average Return = 0.0\n",
      "step = 1950000: loss = 0.0\n",
      "step = 1950000: Average Return = 0.0\n",
      "step = 1960000: loss = 0.0\n",
      "step = 1960000: Average Return = 0.0\n",
      "step = 1970000: loss = 0.0\n",
      "step = 1970000: Average Return = 0.0\n",
      "step = 1980000: loss = 0.0\n",
      "step = 1980000: Average Return = 0.0\n",
      "step = 1990000: loss = 0.0\n",
      "step = 1990000: Average Return = 0.0\n",
      "step = 2000000: loss = 0.0\n",
      "step = 2000000: Average Return = 0.0\n",
      "step = 2010000: loss = 0.0\n",
      "step = 2010000: Average Return = 0.0\n",
      "step = 2020000: loss = 0.0\n",
      "step = 2020000: Average Return = 0.0\n",
      "step = 2030000: loss = 0.0\n",
      "step = 2030000: Average Return = 0.0\n",
      "step = 2040000: loss = 0.0\n",
      "step = 2040000: Average Return = 0.0\n",
      "step = 2050000: loss = 0.0\n",
      "step = 2050000: Average Return = 0.0\n",
      "step = 2060000: loss = 0.0\n",
      "step = 2060000: Average Return = 0.0\n",
      "step = 2070000: loss = 0.0\n",
      "step = 2070000: Average Return = 0.0\n",
      "step = 2080000: loss = 0.0\n",
      "step = 2080000: Average Return = 0.0\n",
      "step = 2090000: loss = 0.0\n",
      "step = 2090000: Average Return = 0.0\n",
      "step = 2100000: loss = 0.0\n",
      "step = 2100000: Average Return = 0.0\n",
      "step = 2110000: loss = 0.0\n",
      "step = 2110000: Average Return = 0.0\n",
      "step = 2120000: loss = 0.0\n",
      "step = 2120000: Average Return = 0.0\n",
      "step = 2130000: loss = 0.0\n",
      "step = 2130000: Average Return = 0.0\n",
      "step = 2140000: loss = 0.0\n",
      "step = 2140000: Average Return = 0.0\n",
      "step = 2150000: loss = 0.0\n",
      "step = 2150000: Average Return = 0.0\n",
      "step = 2160000: loss = 0.0\n",
      "step = 2160000: Average Return = 0.0\n",
      "step = 2170000: loss = 0.0\n",
      "step = 2170000: Average Return = 0.0\n",
      "step = 2180000: loss = 0.0\n",
      "step = 2180000: Average Return = 0.0\n",
      "step = 2190000: loss = 0.0\n",
      "step = 2190000: Average Return = 0.0\n",
      "step = 2200000: loss = 0.0\n",
      "step = 2200000: Average Return = 0.0\n",
      "step = 2210000: loss = 0.0\n",
      "step = 2210000: Average Return = 0.0\n",
      "step = 2220000: loss = 0.0\n",
      "step = 2220000: Average Return = 0.0\n",
      "step = 2230000: loss = 0.0\n",
      "step = 2230000: Average Return = 0.0\n",
      "step = 2240000: loss = 0.0\n",
      "step = 2240000: Average Return = 0.0\n",
      "step = 2250000: loss = 0.0\n",
      "step = 2250000: Average Return = 0.0\n",
      "step = 2260000: loss = 0.0\n",
      "step = 2260000: Average Return = 0.0\n",
      "step = 2270000: loss = 0.0\n",
      "step = 2270000: Average Return = 0.0\n",
      "step = 2280000: loss = 0.0\n",
      "step = 2280000: Average Return = 0.0\n",
      "step = 2290000: loss = 0.0\n",
      "step = 2290000: Average Return = 0.0\n",
      "step = 2300000: loss = 0.0\n",
      "step = 2300000: Average Return = 0.0\n",
      "step = 2310000: loss = 0.0\n",
      "step = 2310000: Average Return = 0.0\n",
      "step = 2320000: loss = 0.0\n",
      "step = 2320000: Average Return = 0.0\n",
      "step = 2330000: loss = 0.0\n",
      "step = 2330000: Average Return = 0.0\n",
      "step = 2340000: loss = 0.0\n",
      "step = 2340000: Average Return = 0.0\n",
      "step = 2350000: loss = 0.0\n",
      "step = 2350000: Average Return = 0.0\n",
      "step = 2360000: loss = 0.0\n",
      "step = 2360000: Average Return = 0.0\n",
      "step = 2370000: loss = 0.0\n",
      "step = 2370000: Average Return = 0.0\n",
      "step = 2380000: loss = 0.0\n",
      "step = 2380000: Average Return = 0.0\n",
      "step = 2390000: loss = 0.0\n",
      "step = 2390000: Average Return = 0.0\n",
      "step = 2400000: loss = 0.0\n",
      "step = 2400000: Average Return = 0.0\n",
      "step = 2410000: loss = 0.0\n",
      "step = 2410000: Average Return = 0.0\n",
      "step = 2420000: loss = 0.0\n",
      "step = 2420000: Average Return = 0.0\n",
      "step = 2430000: loss = 0.0\n",
      "step = 2430000: Average Return = 0.0\n",
      "step = 2440000: loss = 0.0\n",
      "step = 2440000: Average Return = 0.0\n",
      "step = 2450000: loss = 0.0\n",
      "step = 2450000: Average Return = 0.0\n",
      "step = 2460000: loss = 0.0\n",
      "step = 2460000: Average Return = 0.0\n",
      "step = 2470000: loss = 0.0\n",
      "step = 2470000: Average Return = 0.0\n",
      "step = 2480000: loss = 0.0\n",
      "step = 2480000: Average Return = 0.0\n",
      "step = 2490000: loss = 0.0\n",
      "step = 2490000: Average Return = 0.0\n",
      "step = 2500000: loss = 0.0\n",
      "step = 2500000: Average Return = 0.0\n",
      "step = 2510000: loss = 0.0\n",
      "step = 2510000: Average Return = 0.0\n",
      "step = 2520000: loss = 0.0\n",
      "step = 2520000: Average Return = 0.0\n",
      "step = 2530000: loss = 0.0\n",
      "step = 2530000: Average Return = 0.0\n",
      "step = 2540000: loss = 0.0\n",
      "step = 2540000: Average Return = 0.0\n",
      "step = 2550000: loss = 0.0\n",
      "step = 2550000: Average Return = 0.0\n",
      "step = 2560000: loss = 0.0\n",
      "step = 2560000: Average Return = 0.0\n",
      "step = 2570000: loss = 0.0\n",
      "step = 2570000: Average Return = 0.0\n",
      "step = 2580000: loss = 0.0\n",
      "step = 2580000: Average Return = 0.0\n",
      "step = 2590000: loss = 0.0\n",
      "step = 2590000: Average Return = 0.0\n",
      "step = 2600000: loss = 0.0\n",
      "step = 2600000: Average Return = 0.0\n",
      "step = 2610000: loss = 0.0\n",
      "step = 2610000: Average Return = 0.0\n",
      "step = 2620000: loss = 0.0\n",
      "step = 2620000: Average Return = 0.0\n",
      "step = 2630000: loss = 0.0\n",
      "step = 2630000: Average Return = 0.0\n",
      "step = 2640000: loss = 0.0\n",
      "step = 2640000: Average Return = 0.0\n",
      "step = 2650000: loss = 0.0\n",
      "step = 2650000: Average Return = 0.0\n",
      "step = 2660000: loss = 0.0\n",
      "step = 2660000: Average Return = 0.0\n",
      "step = 2670000: loss = 0.0\n",
      "step = 2670000: Average Return = 0.0\n",
      "step = 2680000: loss = 0.0\n",
      "step = 2680000: Average Return = 0.0\n",
      "step = 2690000: loss = 0.0\n",
      "step = 2690000: Average Return = 0.0\n",
      "step = 2700000: loss = 0.0\n",
      "step = 2700000: Average Return = 0.0\n",
      "step = 2710000: loss = 0.0\n",
      "step = 2710000: Average Return = 0.0\n",
      "step = 2720000: loss = 0.0\n",
      "step = 2720000: Average Return = 0.0\n",
      "step = 2730000: loss = 0.0\n",
      "step = 2730000: Average Return = 0.0\n",
      "step = 2740000: loss = 0.0\n",
      "step = 2740000: Average Return = 0.0\n",
      "step = 2750000: loss = 0.0\n",
      "step = 2750000: Average Return = 0.0\n",
      "step = 2760000: loss = 0.0\n",
      "step = 2760000: Average Return = 0.0\n",
      "step = 2770000: loss = 0.0\n",
      "step = 2770000: Average Return = 0.0\n",
      "step = 2780000: loss = 0.0\n",
      "step = 2780000: Average Return = 0.0\n",
      "step = 2790000: loss = 0.0\n",
      "step = 2790000: Average Return = 0.0\n",
      "step = 2800000: loss = 0.0\n",
      "step = 2800000: Average Return = 0.0\n",
      "step = 2810000: loss = 0.0\n",
      "step = 2810000: Average Return = 0.0\n",
      "step = 2820000: loss = 0.0\n",
      "step = 2820000: Average Return = 0.0\n",
      "step = 2830000: loss = 0.0\n",
      "step = 2830000: Average Return = 0.0\n",
      "step = 2840000: loss = 0.0\n",
      "step = 2840000: Average Return = 0.0\n",
      "step = 2850000: loss = 0.0\n",
      "step = 2850000: Average Return = 0.0\n",
      "step = 2860000: loss = 0.0\n",
      "step = 2860000: Average Return = 0.0\n",
      "step = 2870000: loss = 0.0\n",
      "step = 2870000: Average Return = 0.0\n",
      "step = 2880000: loss = 0.0\n",
      "step = 2880000: Average Return = 0.0\n",
      "step = 2890000: loss = 0.0\n",
      "step = 2890000: Average Return = 0.0\n",
      "step = 2900000: loss = 0.0\n",
      "step = 2900000: Average Return = 0.0\n",
      "step = 2910000: loss = 0.0\n",
      "step = 2910000: Average Return = 0.0\n",
      "step = 2920000: loss = 0.0\n",
      "step = 2920000: Average Return = 0.0\n",
      "step = 2930000: loss = 0.0\n",
      "step = 2930000: Average Return = 0.0\n",
      "step = 2940000: loss = 0.0\n",
      "step = 2940000: Average Return = 0.0\n",
      "step = 2950000: loss = 0.0\n",
      "step = 2950000: Average Return = 0.0\n",
      "step = 2960000: loss = 0.0\n",
      "step = 2960000: Average Return = 0.0\n",
      "step = 2970000: loss = 0.0\n",
      "step = 2970000: Average Return = 0.0\n",
      "step = 2980000: loss = 0.0\n",
      "step = 2980000: Average Return = 0.0\n",
      "step = 2990000: loss = 0.0\n",
      "step = 2990000: Average Return = 0.0\n",
      "step = 3000000: loss = 0.0\n",
      "step = 3000000: Average Return = 0.0\n",
      "step = 3010000: loss = 0.0\n",
      "step = 3010000: Average Return = 0.0\n",
      "step = 3020000: loss = 0.0\n",
      "step = 3020000: Average Return = 0.0\n",
      "step = 3030000: loss = 0.0\n",
      "step = 3030000: Average Return = 0.0\n",
      "step = 3040000: loss = 0.0\n",
      "step = 3040000: Average Return = 0.0\n",
      "step = 3050000: loss = 0.0\n",
      "step = 3050000: Average Return = 0.0\n",
      "step = 3060000: loss = 0.0\n",
      "step = 3060000: Average Return = 0.0\n",
      "step = 3070000: loss = 0.0\n",
      "step = 3070000: Average Return = 0.0\n",
      "step = 3080000: loss = 0.0\n",
      "step = 3080000: Average Return = 0.0\n",
      "step = 3090000: loss = 0.0\n",
      "step = 3090000: Average Return = 0.0\n",
      "step = 3100000: loss = 0.0\n",
      "step = 3100000: Average Return = 0.0\n",
      "step = 3110000: loss = 0.0\n",
      "step = 3110000: Average Return = 0.0\n",
      "step = 3120000: loss = 0.0\n",
      "step = 3120000: Average Return = 0.0\n",
      "step = 3130000: loss = 0.0\n",
      "step = 3130000: Average Return = 0.0\n",
      "step = 3140000: loss = 0.0\n",
      "step = 3140000: Average Return = 0.0\n",
      "step = 3150000: loss = 0.0\n",
      "step = 3150000: Average Return = 0.0\n",
      "step = 3160000: loss = 0.0\n",
      "step = 3160000: Average Return = 0.0\n",
      "step = 3170000: loss = 0.0\n",
      "step = 3170000: Average Return = 0.0\n",
      "step = 3180000: loss = 0.0\n",
      "step = 3180000: Average Return = 0.0\n",
      "step = 3190000: loss = 0.0\n",
      "step = 3190000: Average Return = 0.0\n",
      "step = 3200000: loss = 0.0\n",
      "step = 3200000: Average Return = 0.0\n",
      "step = 3210000: loss = 0.0\n",
      "step = 3210000: Average Return = 0.0\n",
      "step = 3220000: loss = 0.0\n",
      "step = 3220000: Average Return = 0.0\n",
      "step = 3230000: loss = 0.0\n",
      "step = 3230000: Average Return = 0.0\n",
      "step = 3240000: loss = 0.0\n",
      "step = 3240000: Average Return = 0.0\n",
      "step = 3250000: loss = 0.0\n",
      "step = 3250000: Average Return = 0.0\n",
      "step = 3260000: loss = 0.0\n",
      "step = 3260000: Average Return = 0.0\n",
      "step = 3270000: loss = 0.0\n",
      "step = 3270000: Average Return = 0.0\n",
      "step = 3280000: loss = 0.0\n",
      "step = 3280000: Average Return = 0.0\n",
      "step = 3290000: loss = 0.0\n",
      "step = 3290000: Average Return = 0.0\n",
      "step = 3300000: loss = 0.0\n",
      "step = 3300000: Average Return = 0.0\n",
      "step = 3310000: loss = 0.0\n",
      "step = 3310000: Average Return = 0.0\n",
      "step = 3320000: loss = 0.0\n",
      "step = 3320000: Average Return = 0.0\n",
      "step = 3330000: loss = 0.0\n",
      "step = 3330000: Average Return = 0.0\n",
      "step = 3340000: loss = 0.0\n",
      "step = 3340000: Average Return = 0.0\n",
      "step = 3350000: loss = 0.0\n",
      "step = 3350000: Average Return = 0.0\n",
      "step = 3360000: loss = 0.0\n",
      "step = 3360000: Average Return = 0.0\n",
      "step = 3370000: loss = 0.0\n",
      "step = 3370000: Average Return = 0.0\n",
      "step = 3380000: loss = 0.0\n",
      "step = 3380000: Average Return = 0.0\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  collect_data(train_env, agent.collect_policy, replay_buffer, collect_steps_per_iteration)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent.train(experience).loss\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1001,) and (339,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_129389/1499355034.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average Return'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iterations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bwsi/venv/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3020\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m~/PycharmProjects/bwsi/venv/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bwsi/venv/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bwsi/venv/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1001,) and (339,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "\n",
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylim(top=250)\n",
    "\n",
    "def embed_mp4(filename):\n",
    "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "  video = open(filename,'rb').read()\n",
    "  b64 = base64.b64encode(video)\n",
    "  tag = '''\n",
    "  <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "  </video>'''.format(b64.decode())\n",
    "\n",
    "  return IPython.display.HTML(tag)\n",
    "\n",
    "def create_policy_eval_video(policy, filename, num_episodes=5, fps=30):\n",
    "  filename = filename + \".mp4\"\n",
    "  with imageio.get_writer(filename, fps=fps) as video:\n",
    "    for _ in range(num_episodes):\n",
    "      time_step = eval_env.reset()\n",
    "      video.append_data(eval_py_env.render())\n",
    "      while not time_step.is_last():\n",
    "        action_step = policy.action(time_step)\n",
    "        time_step = eval_env.step(action_step.action)\n",
    "        video.append_data(eval_py_env.render())\n",
    "  return embed_mp4(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action 1\n",
      "reward -1\n",
      "action 1\n",
      "reward -2\n",
      "action 1\n",
      "reward -2\n",
      "action 2\n",
      "reward -3\n",
      "action 3\n",
      "reward -4\n",
      "action 0\n",
      "reward -4\n",
      "action 3\n",
      "reward -5\n",
      "action 2\n",
      "reward -5\n",
      "action 1\n",
      "reward -20\n",
      "action 0\n",
      "reward -20\n",
      "action 3\n",
      "reward -21\n",
      "action 3\n",
      "reward -26\n",
      "action 3\n",
      "reward -26\n",
      "action 3\n",
      "reward -26\n",
      "action 2\n",
      "reward -24\n",
      "action 2\n",
      "reward -22\n",
      "action 1\n",
      "reward -37\n",
      "action 1\n",
      "reward -37\n",
      "action 3\n",
      "reward -37\n",
      "action 3\n",
      "reward -37\n",
      "action 2\n",
      "reward -37\n",
      "action 3\n",
      "reward -37\n",
      "action 2\n",
      "reward -37\n",
      "action 0\n",
      "reward -37\n"
     ]
    }
   ],
   "source": [
    "# create_policy_eval_video(agent.policy, \"trained-agent\")\n",
    "# agent.save_weights('lovelyweights1')\n",
    "# eval_py_env.save_weights('lovelyweights2')\n",
    "\n",
    "from gym_sgw.envs.enums.Enums import Terrains, MapColors, MapObjects\n",
    "import pygame as pg\n",
    "pg.init()\n",
    "game_screen = pg.display.set_mode((1000, 800))\n",
    "play_area = pg.Surface((10 * 30, 10 * 30))\n",
    "play_area.fill(pg.color.Color(MapColors.play_area.value))\n",
    "game_screen.fill(pg.color.Color(MapColors.game_screen.value))\n",
    "\n",
    "time_step = eval_env.reset()\n",
    "while not time_step.is_last():\n",
    "    for event in pg.event.get():\n",
    "        if event.type == pg.KEYDOWN:\n",
    "            if event.key == pg.K_ESCAPE:\n",
    "                game_exit = True\n",
    "                pg.quit()\n",
    "            if event.key in [pg.K_SPACE, pg.K_KP_ENTER, pg.K_UP, pg.K_DOWN, pg.K_LEFT, pg.K_RIGHT,pg.K_w, pg.K_a, pg.K_s, pg.K_d, pg.K_0, pg.K_1, pg.K_2, pg.K_3]:\n",
    "                action_step = random_policy.action(time_step)\n",
    "                print(\"action\",int(action_step.action))\n",
    "                time_step = eval_env.step(action_step.action)\n",
    "                print(\"reward\",int(time_step.reward))\n",
    "                # eval_env._env._envs[0].step(int(action_step.action))\n",
    "                s = list(time_step.observation)[0]\n",
    "                # print(\"hey there im actually kinda important:\")\n",
    "                # print(eval_env._env._envs)\n",
    "                # print(eval_env._env._envs[0])\n",
    "                # print(eval_env._env._envs[0].get_map())\n",
    "                map_text = eval_env._env._envs[0].get_map()\n",
    "                # print(eval_env.pyenv.get_map())\n",
    "                ahh = []\n",
    "                for x in range(10):\n",
    "                        z = s[x*10:(x+1)*10]\n",
    "                        ahh.append(z)                \n",
    "                # print(ahh)\n",
    "                for r_ in range(10):\n",
    "                    for c_ in range(10):\n",
    "                        cell = int(str(int(ahh[r_][c_]))[0])\n",
    "                        if cell == Terrains.none:\n",
    "                            cell_color = pg.color.Color(MapColors.black_tile.value)\n",
    "                        elif cell == Terrains.out_of_bounds:\n",
    "                            cell_color = pg.color.Color(MapColors.black_tile.value)\n",
    "                        elif cell == Terrains.wall:\n",
    "                            cell_color = pg.color.Color(MapColors.wall_tile.value)\n",
    "                        elif cell == Terrains.floor:\n",
    "                            cell_color = pg.color.Color(MapColors.floor_tile.value)\n",
    "                        elif cell == Terrains.mud:\n",
    "                            cell_color = pg.color.Color(MapColors.mud_tile.value)\n",
    "                        elif cell == Terrains.fire:\n",
    "                            cell_color = pg.color.Color(MapColors.fire_tile.value)\n",
    "                        elif cell == Terrains.hospital:\n",
    "                            cell_color = pg.color.Color(MapColors.hospital_tile.value)\n",
    "                        else:\n",
    "                            raise ValueError('Invalid cell terrain while rendering game image.')\n",
    "\n",
    "                        # Draw the rectangle with the right color for the terrains\n",
    "                        # rect is play area, color, and (left point, top point, width, height)\n",
    "                        pg.draw.rect(play_area, cell_color, (c_ * 30, r_ * 30,\n",
    "                                                                30, 30))\n",
    "                        game_screen.blit(play_area, play_area.get_rect())\n",
    "\n",
    "                        # Add in the cell value string\n",
    "                        pg.font.init()\n",
    "\n",
    "                        cell_font = pg.font.SysFont(pg.font.get_default_font(), 20)\n",
    "                        \n",
    "                        text_surf = cell_font.render(map_text[r_][c_], True, pg.color.Color(MapColors.text.value))\n",
    "                        play_area.blit(text_surf, ((c_ * 30) + 30 // 2,\n",
    "                                                        (r_ * 30) + 30 // 2))\n",
    "                        pg.display.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_121568/2672578377.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgame_screen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMapColors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_screen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtime_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_last\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_env' is not defined"
     ]
    }
   ],
   "source": [
    "# create_policy_eval_video(random_policy, \"random-agent\")\n",
    "\n",
    "# create_policy_eval_video(agent.policy, \"trained-agent\")\n",
    "# agent.save_weights('lovelyweights1')\n",
    "# eval_py_env.save_weights('lovelyweights2')\n",
    "\n",
    "from gym_sgw.envs.enums.Enums import Terrains, MapColors, MapObjects\n",
    "import pygame as pg\n",
    "pg.init()\n",
    "game_screen = pg.display.set_mode((1000, 800))\n",
    "play_area = pg.Surface((10 * 30, 10 * 30))\n",
    "play_area.fill(pg.color.Color(MapColors.play_area.value))\n",
    "game_screen.fill(pg.color.Color(MapColors.game_screen.value))\n",
    "\n",
    "time_step = eval_env.reset()\n",
    "while not time_step.is_last():\n",
    "    for event in pg.event.get():\n",
    "        if event.type == pg.KEYDOWN:\n",
    "            if event.key == pg.K_ESCAPE:\n",
    "                game_exit = True\n",
    "                pg.quit()\n",
    "            if event.key in [pg.K_SPACE, pg.K_KP_ENTER, pg.K_UP, pg.K_DOWN, pg.K_LEFT, pg.K_RIGHT,pg.K_w, pg.K_a, pg.K_s, pg.K_d, pg.K_0, pg.K_1, pg.K_2, pg.K_3]:\n",
    "                action_step = random_policy.action(time_step)\n",
    "                print(\"action\",int(action_step.action))\n",
    "                time_step = eval_env.step(action_step.action)\n",
    "                print(\"reward\",int(time_step.reward))\n",
    "                eval_env._env._envs[0].step(int(action_step.action))\n",
    "                s = list(time_step.observation)[0]\n",
    "                # print(\"hey there im actually kinda important:\")\n",
    "                # print(eval_env._env._envs)\n",
    "                # print(eval_env._env._envs[0])\n",
    "                # print(eval_env._env._envs[0].get_map())\n",
    "                map_text = eval_env._env._envs[0].get_map()\n",
    "                # print(eval_env.pyenv.get_map())\n",
    "                ahh = []\n",
    "                for x in range(10):\n",
    "                        z = s[x*10:(x+1)*10]\n",
    "                        ahh.append(z)                \n",
    "                # print(ahh)\n",
    "                for r_ in range(10):\n",
    "                    for c_ in range(10):\n",
    "                        cell = int(str(int(ahh[r_][c_]))[0])\n",
    "                        if cell == Terrains.none:\n",
    "                            cell_color = pg.color.Color(MapColors.black_tile.value)\n",
    "                        elif cell == Terrains.out_of_bounds:\n",
    "                            cell_color = pg.color.Color(MapColors.black_tile.value)\n",
    "                        elif cell == Terrains.wall:\n",
    "                            cell_color = pg.color.Color(MapColors.wall_tile.value)\n",
    "                        elif cell == Terrains.floor:\n",
    "                            cell_color = pg.color.Color(MapColors.floor_tile.value)\n",
    "                        elif cell == Terrains.mud:\n",
    "                            cell_color = pg.color.Color(MapColors.mud_tile.value)\n",
    "                        elif cell == Terrains.fire:\n",
    "                            cell_color = pg.color.Color(MapColors.fire_tile.value)\n",
    "                        elif cell == Terrains.hospital:\n",
    "                            cell_color = pg.color.Color(MapColors.hospital_tile.value)\n",
    "                        else:\n",
    "                            raise ValueError('Invalid cell terrain while rendering game image.')\n",
    "\n",
    "                        # Draw the rectangle with the right color for the terrains\n",
    "                        # rect is play area, color, and (left point, top point, width, height)\n",
    "                        pg.draw.rect(play_area, cell_color, (c_ * 30, r_ * 30,\n",
    "                                                                30, 30))\n",
    "                        game_screen.blit(play_area, play_area.get_rect())\n",
    "\n",
    "                        # Add in the cell value string\n",
    "                        pg.font.init()\n",
    "\n",
    "                        cell_font = pg.font.SysFont(pg.font.get_default_font(), 20)\n",
    "                        \n",
    "                        text_surf = cell_font.render(map_text[r_][c_], True, pg.color.Color(MapColors.text.value))\n",
    "                        play_area.blit(text_surf, ((c_ * 30) + 30 // 2,\n",
    "                                                        (r_ * 30) + 30 // 2))\n",
    "                        pg.display.update()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv')",
   "name": "pythonjvsc74a57bd0b799b3996f02a7001cf1e2ccf289e4ee214240a8cfd86448e5d8fdb60696149f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "b799b3996f02a7001cf1e2ccf289e4ee214240a8cfd86448e5d8fdb60696149f"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}